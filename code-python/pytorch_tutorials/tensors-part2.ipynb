{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dd79c24",
   "metadata": {},
   "source": [
    "# Create Tensors of Zero's and One's"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003bfe3c",
   "metadata": {},
   "source": [
    "0 and 1 tensors are backbone for placeholder, test data and initializing models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b4f2339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bfce1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zeros 1D tensor :  tensor([0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# Zeros tensor\n",
    "\n",
    "zeros_tensor = torch.zeros(5) # 1D vector\n",
    "print(\"Zeros 1D tensor : \", zeros_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f500856b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zeros 2D tensor : \n",
      " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Zeros 2D tensor Shape:  torch.Size([256, 256])\n"
     ]
    }
   ],
   "source": [
    "# Multi dimensional\n",
    "zeros_tensor = torch.zeros(256, 256) # 2D vector\n",
    "print(\"Zeros 2D tensor : \\n\", zeros_tensor)\n",
    "print(\"Zeros 2D tensor Shape: \", zeros_tensor.shape)\n",
    "print(\"Zeros 2D tensor Dimension: \", zeros_tensor.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87cfb573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Since the tensor is 2D it can be seen as an image\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(zeros_tensor.numpy(), cmap='grey', vmin=0, vmax=1) \n",
    "# specify min and max since it try to normalize the values in 0-1\n",
    "# Since it is full of zeros, it is black \n",
    "plt.title(\"Dark Image\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e61862a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones 1D tensor :  tensor([1., 1., 1., 1., 1.])\n",
      "Ones 2D tensor : \n",
      " tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]])\n",
      "Ones 2D tensor Shape:  torch.Size([256, 256])\n",
      "Ones 2D tensor Dimension:  2\n"
     ]
    }
   ],
   "source": [
    "# Tensors of ones\n",
    "\n",
    "# 1 D\n",
    "ones_tensor = torch.ones(5) # 1D vector\n",
    "print(\"Ones 1D tensor : \", ones_tensor)\n",
    "\n",
    "# Multi dimensional\n",
    "ones_tensor = torch.ones(256, 256) # 2D vector\n",
    "print(\"Ones 2D tensor : \\n\", ones_tensor)\n",
    "print(\"Ones 2D tensor Shape: \", ones_tensor.shape)\n",
    "print(\"Ones 2D tensor Dimension: \", ones_tensor.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b378c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Since the tensor is 2D it can be seen as an image\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(ones_tensor.numpy(), cmap='grey', vmin=0, vmax=1) \n",
    "# plt.imshow(ones_tensor.numpy(), cmap='grey') # If I don't specify vmin,vmax it will seems balck since it is normalized and not correct\n",
    "# specify min and max since it try to normalize the values in 0-1\n",
    "# Since it is full of zeros, it is black \n",
    "plt.title(\"Bright Image\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c860d3",
   "metadata": {},
   "source": [
    "# Tensor DataTypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3b72c8",
   "metadata": {},
   "source": [
    "Different tensors data types influence performance, precision and memory usage "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e9b936",
   "metadata": {},
   "source": [
    "data types for tensors \n",
    "base data types as float, int, bool ...\n",
    "\n",
    "**floating**: is used for most of deep learning tasks --> float32, float64, float16 (based on memory consumption and computation)\n",
    "\n",
    "**integer**:  is used for cathegorigal data or indices of tensors/lists --> int32, int64, int8\n",
    "\n",
    "**boolean**:  is used to create masks or logical operations\n",
    "\n",
    "**complex numbers**: used for advance computation --> complex64, complex128\n",
    "\n",
    "\n",
    "chosing the correct data type influence the performance\n",
    "\n",
    "\n",
    "**memory consumption** clearly float16 use less memory than float32 and float64\n",
    "\n",
    "**computation** : lower precision is faster on GPU \n",
    "\n",
    "**numerical precision**: float64 more precise than float32 (carry more bits, more data and more precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e83f2cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensors with different data types \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4957acec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type by default :  torch.float32\n"
     ]
    }
   ],
   "source": [
    "default_tensor = torch.tensor([1.5, 2.5, 3.5])\n",
    "# by default float32 is used in floating numbers \n",
    "print(\"Data type by default : \", default_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfd7287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type custom :  torch.float64\n"
     ]
    }
   ],
   "source": [
    "# To specify dtype explicitly\n",
    "float_tensor = torch.tensor([1.5, 2.5, 3.5], dtype=torch.float64)\n",
    "\n",
    "print(\"Data type custom : \", float_tensor.dtype) # In this case it is of the type defined "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e987d54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted Tensor:  tensor([1, 2, 3], dtype=torch.int32)\n",
      "Data type Int tensor :  torch.int32\n"
     ]
    }
   ],
   "source": [
    "# To specify dtype explicitly\n",
    "int_tensor = torch.tensor([1.5, 2.5, 3.6], dtype=torch.int32)\n",
    "\n",
    "print('Converted Tensor: ', int_tensor) # Lose decimal point\n",
    "print(\"Data type Int tensor : \", int_tensor.dtype) # In this case it is of the type defined "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79bdcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted Tensor:  tensor([1, 2, 3])\n",
      "Data type Int tensor :  torch.int64\n"
     ]
    }
   ],
   "source": [
    "# To specify dtype explicitly\n",
    "int_tensor = torch.tensor([1, 2, 3])\n",
    "\n",
    "print('Int Tensor: ', int_tensor) \n",
    "print(\"Data type Int tensor : \", int_tensor.dtype) \n",
    "# By default if initialized with non floating numbers it is stored as int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0dd915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bol Tensor:  tensor([ True, False,  True])\n",
      "Data type Bool tensor :  torch.bool\n"
     ]
    }
   ],
   "source": [
    "# Create boolean tensor \n",
    "#bool_tensor = torch.tensor([True, False, True], dtype=torch.bool) # You can specify the dtype otherwise it is defined by default \n",
    "\n",
    "bool_tensor = torch.tensor([True, False, True])\n",
    "\n",
    "print('Bool Tensor: ', bool_tensor) \n",
    "print(\"Data type Bool tensor : \", bool_tensor.dtype) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c28e863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to convert between data types "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu12_8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
