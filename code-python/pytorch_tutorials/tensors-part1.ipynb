{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "259251ad",
   "metadata": {},
   "source": [
    "# Introduction to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "617625bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6795f6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scalar Tensor :  tensor(42)\n",
      "Scalar Dimension :  0\n",
      "Scalar Shape :  torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "# Creating Tensors\n",
    "\n",
    "# Scalar Tensor (0 dimension tensor) 0D\n",
    "\n",
    "a = 42 # python scalar\n",
    "# scalar tensor\n",
    "scalar = torch.tensor(42)\n",
    "\n",
    "print(\"Scalar Tensor : \",    scalar)\n",
    "print(\"Scalar Dimension : \", scalar.ndim)\n",
    "print(\"Scalar Shape : \",     scalar.shape) # No shape since it is scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d91c0978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Tensor :  tensor([1, 2, 3])\n",
      "Vector Dimension :  1\n",
      "Vector Shape :  torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# One Dimensional Tensor 1D: Vector\n",
    "\n",
    "vector = torch.tensor([1, 2, 3]) # we pass a list to create a one dimensional vector\n",
    "\n",
    "print(\"Vector Tensor : \",    vector)\n",
    "print(\"Vector Dimension : \", vector.ndim)  # number of dimension \n",
    "print(\"Vector Shape : \",     vector.shape)     # single dimension with 3 elements its dimension, get its size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c39fdb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Tensor :  tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "Matrix Dimension :  2\n",
      "Matrix Shape :  torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Two Dimensional Tensor 2D: Matrix \n",
    "\n",
    "matrix = torch.tensor([[1, 2], [3, 4]]) # we pass a list of list to create a two dimensional tensor\n",
    "\n",
    "print(\"Matrix Tensor : \",    matrix)\n",
    "print(\"Matrix Dimension : \", matrix.ndim)  # number of dimension \n",
    "print(\"Matrix Shape : \",     matrix.shape) # single dimension with 2x2 elements its dimension, get its size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5fb42f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor :  tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[1, 2],\n",
      "         [3, 4]]])\n",
      "Tensor Dimension :  3\n",
      "Tensor Shape :  torch.Size([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Three Dimensional Tensor 3D: Tensor\n",
    "# Any tensor of more than 2D is a Tensor \n",
    "\n",
    "tensor3d = torch.tensor(  [[[1, 2], [3, 4]], # we pass a list of list of list to create a three dimensional tensor\n",
    "                         [[1, 2], [3, 4]]]\n",
    "                      ) \n",
    "\n",
    "print(\"Tensor : \",    tensor3d)\n",
    "print(\"Tensor Dimension : \", tensor3d.ndim)  # number of dimension \n",
    "print(\"Tensor Shape : \",     tensor3d.shape) # single dimension with 2x2x2 elements its dimension, get its size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5750f54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor on GPU:  tensor([1, 2, 3], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# When working with Tensors, PyTorch has additional capabilities then other python framework as numpy \n",
    "# such as running computation on GPU \n",
    "\n",
    "# GPU acceleration \n",
    "\n",
    "# First check if cuda is available \n",
    "if torch.cuda.is_available():\n",
    "    gpu_tensor = vector.to('cuda') # move tensor to GPU \n",
    "    print(\"Tensor on GPU: \", gpu_tensor)\n",
    "\n",
    "else:\n",
    "    print(\"CUDA is not available on this machine\")\n",
    "\n",
    "# cuda: 0 indicate the main GPU, if multiple GPU are available more index of cuda are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca96ec52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of matrix :  torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Check Tensor Properties\n",
    "\n",
    "# other than ndim, shape..\n",
    "\n",
    "print(\"Data type of matrix : \", matrix.dtype)\n",
    "# by default using int64 (no floating point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f78ba939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of matrix :  torch.float32\n"
     ]
    }
   ],
   "source": [
    "matrix = torch.tensor([[1., 2.], [3, 4]]) # we pass a list of list to create a two dimensional tensor\n",
    "print(\"Data type of matrix : \", matrix.dtype)\n",
    "# change it to float32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c0fd590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device of Tensor :  cpu\n",
      "Device of Tensor :  cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Check device\n",
    "print(\"Device of Tensor : \", matrix.device)\n",
    "print(\"Device of Tensor : \", gpu_tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f13e0aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan 22 10:15:08 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.195.03             Driver Version: 570.195.03     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX PRO 500 Black...    Off |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   44C    P4             10W /   50W |     785MiB /   6113MiB |     10%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            2695      G   /usr/lib/xorg/Xorg                      205MiB |\n",
      "|    0   N/A  N/A            3154      G   /usr/bin/gnome-shell                     87MiB |\n",
      "|    0   N/A  N/A            4278      G   ...rack-uuid=3190708988185955192        111MiB |\n",
      "|    0   N/A  N/A            9933      G   /proc/self/exe                          162MiB |\n",
      "|    0   N/A  N/A           10690      C   ...da3/envs/torch_env/bin/python         68MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae0effbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is tensor on CUDA :  False\n",
      "Is tensor on CUDA :  True\n"
     ]
    }
   ],
   "source": [
    "# check boolean if stored on boolean\n",
    "# Doesn't return specific device, but boolean check\n",
    "print(\"Is tensor on CUDA : \", matrix.is_cuda)\n",
    "print(\"Is tensor on CUDA : \", gpu_tensor.is_cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90de28d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape :  torch.Size([2, 2])\n",
      "Size :  torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Shape internally rely on size\n",
    "print(\"Shape : \", matrix.shape)\n",
    "print(\"Size : \", matrix.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fffa694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements :  4\n"
     ]
    }
   ],
   "source": [
    "# Check number of elements in a tensor \n",
    "print(\"Number of elements : \", matrix.numel())\n",
    "# 2x2 matrix = 4 elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6eaa92d",
   "metadata": {},
   "source": [
    "# Indexing Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d26beb3",
   "metadata": {},
   "source": [
    "How to perform indexing and slicing, \n",
    "to efficently accessing, manipulating and analyzing data stored in tensors. \n",
    "\n",
    "Indexing and Slicing is done in the same way as for lists and numpy array, with additional flexibility for multi dimensional array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9e4d4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of Tensor :  2\n",
      "Shape of Tensor :  torch.Size([3, 3])\n",
      "Element at (0,1) :  tensor(20)\n",
      "First row :  tensor([10, 20, 30])\n",
      "First column :  tensor([10, 40, 70])\n"
     ]
    }
   ],
   "source": [
    "# Accessing elements in a tensor \n",
    "# Indexing\n",
    "'''\n",
    "tensor[row, column] : to access a specfic element\n",
    "'''\n",
    "\n",
    "tensor = torch.tensor([[10, 20, 30], \n",
    "                       [40, 50, 60], \n",
    "                       [70, 80, 90]])\n",
    "\n",
    "print(\"Dimension of Tensor : \", tensor.ndim)\n",
    "print(\"Shape of Tensor : \", tensor.shape)\n",
    "\n",
    "# access single element\n",
    "print(\"Element at (0,1) : \", tensor[0, 1])\n",
    "# it return a scalare tensor value by accessing a specific element inside of a tensor\n",
    "\n",
    "# access full first row \n",
    "print(\"First row : \", tensor[0])\n",
    "\n",
    "# access full first column (slicing all rows from first column)\n",
    "print(\"First column : \", tensor[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d217174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First two rows : \n",
      " tensor([[10, 20, 30],\n",
      "        [40, 50, 60]])\n",
      "First two columns : \n",
      " tensor([[10, 20],\n",
      "        [40, 50],\n",
      "        [70, 80]])\n"
     ]
    }
   ],
   "source": [
    "# Slicing operation \n",
    "# to select specific range of values \n",
    "\n",
    "# when slicing it exclude the right limit\n",
    "print(\"First two rows : \\n\", tensor[:2]) # take all columns by default, no need to refer to specific columns of interest \n",
    "\n",
    "print(\"First two columns : \\n\", tensor[:, :2]) # take all rows and slice columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a1516aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second row,  columns 1 and 2: tensor([50, 60])\n"
     ]
    }
   ],
   "source": [
    "# Get specific rows, cols slice\n",
    "print(\"Second row,  columns 1 and 2:\", tensor[1, 1:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d552efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values in [0,1] and [2,2] :  tensor([20, 90])\n"
     ]
    }
   ],
   "source": [
    "# \"Fancy indexing\"\n",
    "# To get value not in sequence but different values out of order in a tensor \n",
    "\n",
    "# get values in [0,1] and [2,2] of the tensor\n",
    "'''\n",
    "tensor[[rows], [columns]] : to access a specfic elements\n",
    "'''\n",
    "print(\"Values in [0,1] and [2,2] : \", tensor[[0,2],[1,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7a31982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask such that values > 50 : \n",
      " tensor([[False, False, False],\n",
      "        [False, False,  True],\n",
      "        [ True,  True,  True]])\n",
      "Tensor of masked values : \n",
      " tensor([60, 70, 80, 90])\n"
     ]
    }
   ],
   "source": [
    "# Boolean indexing, using boolean mask to access specific values \n",
    "\n",
    "# create a boolean mask with conditional statement \n",
    "mask = tensor > 50\n",
    "print(\"mask such that values > 50 : \\n\", mask)\n",
    "\n",
    "# access only value respecing the mask \n",
    "print(\"Tensor of masked values : \\n\", tensor[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a68fd50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Originally: \n",
      " tensor([[10, 20, 30],\n",
      "        [40, 50, 60],\n",
      "        [70, 80, 90]])\n",
      "Tensor Modified: \n",
      " tensor([[10, 25, 30],\n",
      "        [40, 50, 60],\n",
      "        [70, 80, 90]])\n"
     ]
    }
   ],
   "source": [
    "# Modify values in the tensor via indexing\n",
    "# instead of just accessing values, update it simply as in lists \n",
    "\n",
    "print(\"Tensor Originally: \\n\", tensor)\n",
    "\n",
    "tensor[0,1] = 25\n",
    "\n",
    "print(\"Tensor Modified: \\n\", tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4f12f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Originally: \n",
      " tensor([[10, 25, 30],\n",
      "        [40, 50, 60],\n",
      "        [70, 80, 90]])\n",
      "Tensor Modified: \n",
      " tensor([[100,  25,  30],\n",
      "        [200,  50,  60],\n",
      "        [300,  80,  90]])\n"
     ]
    }
   ],
   "source": [
    "# In the same way values can be changed in batch\n",
    "print(\"Tensor Originally: \\n\", tensor)\n",
    "\n",
    "tensor[:,0] = torch.tensor([100, 200, 300]) # change the first column \n",
    "\n",
    "print(\"Tensor Modified: \\n\", tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c27eadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select rows : \n",
      "  tensor([[100,  25,  30],\n",
      "        [300,  80,  90]])\n",
      "Select columns : \n",
      "  tensor([[100,  30],\n",
      "        [200,  60],\n",
      "        [300,  90]])\n"
     ]
    }
   ],
   "source": [
    "# Advanced slicing with torch.index_select \n",
    "# more adavances slicing is possible \n",
    "\n",
    "indices = torch.tensor([0,2])\n",
    "# after defining the indices to select\n",
    "# dim=0 specify that the selection is based on the rows (dim=1 is columns)\n",
    "selected_rows = torch.index_select(tensor, dim=0, index=indices)\n",
    "print(\"Select rows : \\n \", selected_rows)\n",
    "\n",
    "selected_columns = torch.index_select(tensor, dim=1, index=indices)\n",
    "print(\"Select columns : \\n \", selected_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "347eb762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step indexing, all rows with step of 2 in columns : \n",
      " tensor([[100,  30],\n",
      "        [200,  60],\n",
      "        [300,  90]])\n"
     ]
    }
   ],
   "source": [
    "# Accessing tensors with steps in slicing  \n",
    "print(\"step indexing, all rows with step of 2 in columns : \\n\", tensor[:, ::2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "566a406c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step indexing, all rows with reverse rows order : \n",
      " tensor([[300,  80,  90],\n",
      "        [200,  50,  60],\n",
      "        [100,  25,  30]])\n"
     ]
    }
   ],
   "source": [
    "print(\"step indexing, all rows with reverse rows order : \\n\", torch.flip(tensor, dims=(0,))) \n",
    "\n",
    "# negative step size doesn't work on tensor differently from numpy (Value Error)\n",
    "# print(\"step indexing, all rows with step of 2 in columns : \\n\", tensor[::-1]) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
