{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2ff74c8",
   "metadata": {},
   "source": [
    "# View and Reshape Operation in Depth \n",
    "\n",
    "Major difference between View and Reshape, both used to change the shape of tensors...\n",
    "\n",
    "Transform the shape keeping data consistent. Both can change the shape, but behaves differently at the memory level\n",
    "\n",
    "(different behavior on te underline data structure)\n",
    "\n",
    "- view: work only on contiguous data tensor (tensor stored contiguously in memory)\n",
    "- reshape: can handle non contiguous tensor data structure, by creating a new one if needed\n",
    "\n",
    "reshape is more flexible, while view is constrained on contiguous\n",
    "\n",
    "\n",
    "### What we mean with contiguou data/tensors ? \n",
    "\n",
    "From an original tensor [[1, 2, 3], [4, 5, 6]] 2x3 stored in memory as a sequence block (left-to-right) as 1,2,3,4,5,6... \n",
    "\n",
    "stored as a flat array in memory (flat list) in this case it is contiguous. \n",
    "contiguous when grid-like structure directly map to the flat memoery in row-major order (left to right and with row index)\n",
    "\n",
    "Grid like structure directly map to flat memory. It respect the order of the original tensor in the data spac.\n",
    "\n",
    "\n",
    "\n",
    "While if from an original data [[1, 2, 3], [4, 5, 6]], when any tensor modification change it order (e.g. transpose, slicing, etc)\n",
    "\n",
    "it get new size [[1, 4], [2, 5], [3, 6]] New value after transposition\n",
    "\n",
    "In memory the value is still stored as [1, 2, 3, 4, 5, 6] but it in pytorch data it is sequenced in row major order as 1 4 2 5 3 6 ordering...\n",
    "\n",
    "\n",
    "Now data is sequenced in a differnet way from the memory ordering.\n",
    "\n",
    "This make the tensor non contiguous: The data remains the same in memory, but the access pattern changes. When indexing it become computationally expensive\n",
    "\n",
    "\n",
    "When working only with contiguous data, we make the code more efficient, better performing (faster) by working with view()\n",
    "\n",
    "\n",
    "Instead with reshape() is less performing since non contiguous is accepted \n",
    "\n",
    "\n",
    "We can only use view when we are confident about contiguity of tensor, and need efficient operation in our system. \n",
    "\n",
    "Reshape can be used when we want robustness and we are unsure about contuguity. It can work also with non-contiguous. \n",
    "\n",
    "\n",
    "Reshape handles non-contiguous data by creating a contiguous copy of it. (If it take a contiguous one, it does reshape directly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fac9373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c76432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original : \n",
      " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
      "\n",
      "View : \n",
      " tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11]])\n",
      "\n",
      "Reshape : \n",
      " tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(12)\n",
    "\n",
    "# try to reshape with both methods: \n",
    "\n",
    "reshaped_view = tensor.view(2, 6)\n",
    "reshaped_reshape = tensor.reshape(2, 6)\n",
    "\n",
    "print(\"Original : \\n\", tensor)\n",
    "\n",
    "print(\"\\nView : \\n\", reshaped_view)\n",
    "\n",
    "print(\"\\nReshape : \\n\", reshaped_reshape)\n",
    "\n",
    "# Same information stored, of new shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e03917c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if contiguous tensors \n",
    "tensor.is_contiguous()\n",
    "# If non-contiguous view() will give an erro while reshape() can run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "025bfe41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It is possible to calculate the shape automatically of reshaping \n",
    "\n",
    "tensor.view(3, -1) # The -1 value indicate to automatically infer the shape based on the original tensor\n",
    "# In this case we specify the number of new rows, while the other diemension is automatically computed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60364b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11]],\n",
      "\n",
      "        [[12, 13, 14, 15],\n",
      "         [16, 17, 18, 19],\n",
      "         [20, 21, 22, 23]]])\n"
     ]
    }
   ],
   "source": [
    "# In CNN after some operations we use vectors...\n",
    "# Given matrix MxN to get 1 x (M) vector we can use -1 to change 3D/2D tensor to 1D vector \n",
    "\n",
    "tensor3d = torch.arange(24).reshape(2, 3, 4) # from a 2x3x4 tensor\n",
    "\n",
    "print(tensor3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc02b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# I want to use this tensor3d as input for a CNN feature ?? \n",
    "# To create 1D tensor from this 3D\n",
    "flattened = tensor3d.view(-1) # specifying -1 it automatically compute the new size \n",
    "\n",
    "print(flattened)\n",
    "print(flattened.is_contiguous()) # Still keeping contiguity after reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca53bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "tensor3d = torch.arange(24).reshape(12,2) # from a 2x3x4 tensor\n",
    "\n",
    "# transpose it to lose contiguity \n",
    "transpose3d = tensor3d.t()\n",
    "\n",
    "print(transpose3d.is_contiguous())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c4c7540",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# the transposed tensor is not contiguous... \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtranspose3d\u001b[49m\u001b[43m.\u001b[49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# try to reshape with view, BUT IT IS NON-CONTUGUOUS\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "# the transposed tensor is not contiguous... \n",
    "transpose3d.view(6, 4) # try to reshape with view, BUT IT IS NON-CONTUGUOUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "472b8391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It suggest to use reshape instead...\n",
    "new = transpose3d.reshape(6, 4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "614f95bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(new.is_contiguous())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae599a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  2,  4,  6],\n",
       "        [ 8, 10, 12, 14],\n",
       "        [16, 18, 20, 22],\n",
       "        [ 1,  3,  5,  7],\n",
       "        [ 9, 11, 13, 15],\n",
       "        [17, 19, 21, 23]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By reshape a contiguous copy is created... \n",
    "# view() works only on contiguous memory and cannot handle non-contiguous...\n",
    "# It is possible to make data contiguous\n",
    "\n",
    "transpose3d = transpose3d.contiguous()\n",
    "transpose3d.view(6, 4) \n",
    "\n",
    "# Now it is create a contiguous version of it where view() can be used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e49b4bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In conclusion, view is more efficient and fast, but not robust\n",
    "# reshape instead degrade performances by creating copies of the tensor to handle non-contiguity..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa53194",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu12_8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
